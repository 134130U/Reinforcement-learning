{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_bandits\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-27 20:24:44,775] Making new env: BanditTenArmedGaussian-v0\n",
      "/home/aims/anaconda3/envs/universe/lib/python3.6/site-packages/gym/envs/registration.py:18: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"BanditTenArmedGaussian-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The epsilon - greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first initialize all the variables\n",
    "\n",
    "num_rounds = 20000\n",
    "\n",
    "count = np.zeros(env.n_bandits)\n",
    "\n",
    "sum_rewards = np.zeros(env.n_bandits)\n",
    "\n",
    "Q = np.zeros(env.n_bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define our epsilon-greedy function\n",
    "\n",
    "def epsilon_greedy(epsilon):\n",
    "    rand = np.random.random()\n",
    "    if rand < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(Q)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal arm is 4\n"
     ]
    }
   ],
   "source": [
    "# Start pulling the arm\n",
    "for i in range(num_rounds):\n",
    "    # Select the arm using epsilon greedy\n",
    "    arm = epsilon_greedy(0.5)\n",
    "    # Get the rewards\n",
    "    observation, reward, done, info = env.step(arm)\n",
    "    # Update the count of that arm\n",
    "    count[arm] +=1 \n",
    "    #Sum the rewards obtained from that arm\n",
    "    sum_rewards[arm] +=reward\n",
    "    #Calculate the Q value which is the average rewards of the arm\n",
    "    Q[arm] = sum_rewards[arm]/count[arm]\n",
    "print('The optimal arm is {}'.format(np.argmax(Q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Softmax exploration algorithm\n",
    "\n",
    "in this softmax algorithm we must specify the value of the temparature factor noted as $\\tau$. It specifies how many random arms we can explore. When $\\tau$ is high, all the arms will be explored equally, but when it is low, only high-rewardin arms will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first initialize all the variables\n",
    "\n",
    "num_rounds = 20000\n",
    "\n",
    "count = np.zeros(env.n_bandits)\n",
    "\n",
    "sum_rewards = np.zeros(env.n_bandits)\n",
    "\n",
    "Q = np.zeros(env.n_bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define the softmax algorithm\n",
    "\n",
    "def softmax(tau):\n",
    "    total = sum([np.exp(val/tau) for val in Q])\n",
    "    probs = [np.exp(val/tau)/total for val in Q]\n",
    "    threshold = np.random.random()\n",
    "    cumulative_prob = 0.0\n",
    "    for i in range(len(probs)):\n",
    "        cumulative_prob += probs[i]\n",
    "        if (cumulative_prob > threshold):\n",
    "            return i\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal arm is 4\n"
     ]
    }
   ],
   "source": [
    "# Start pulling the arm\n",
    "for i in range(num_rounds):\n",
    "    # Select the arm using softmax\n",
    "    arm = softmax(0.5)\n",
    "    # Get the rewards\n",
    "    observation, reward, done, info = env.step(arm)\n",
    "    # Update the count of that arm\n",
    "    count[arm] +=1 \n",
    "    #Sum the rewards obtained from that arm\n",
    "    sum_rewards[arm] +=reward\n",
    "    #Calculate the Q value which is the average rewards of the arm\n",
    "    Q[arm] = sum_rewards[arm]/count[arm]\n",
    "print('The optimal arm is {}'.format(np.argmax(Q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The upper confidence bound algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first initialize all the variables\n",
    "\n",
    "num_rounds = 20000\n",
    "\n",
    "count = np.zeros(env.n_bandits)\n",
    "\n",
    "sum_rewards = np.zeros(env.n_bandits)\n",
    "\n",
    "Q = np.zeros(env.n_bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCB(iters):\n",
    "    ucb = np.zeros(env.n_bandits)\n",
    "    #let's explore all the arms\n",
    "    if iters <env.n_bandits:\n",
    "        return iters\n",
    "    else:\n",
    "        for arm in range(env.n_bandits):\n",
    "            #compute the upper bound\n",
    "            upper_bound = np.sqrt(2*np.log(sum(count))/count[arm])\n",
    "            ucb[arm] = Q[arm] + upper_bound\n",
    "        #return the arm which has maximum value\n",
    "        return np.argmax(ucb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal arm is 4\n"
     ]
    }
   ],
   "source": [
    "# Start pulling the arm\n",
    "for i in range(num_rounds):\n",
    "    # Select the arm using UCB\n",
    "    arm = UCB(i)\n",
    "    # Get the rewards\n",
    "    observation, reward, done, info = env.step(arm)\n",
    "    # Update the count of that arm\n",
    "    count[arm] +=1 \n",
    "    #Sum the rewards obtained from that arm\n",
    "    sum_rewards[arm] +=reward\n",
    "    #Calculate the Q value which is the average rewards of the arm\n",
    "    Q[arm] = sum_rewards[arm]/count[arm]\n",
    "print('The optimal arm is {}'.format(np.argmax(Q))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson sampling algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first initialize all the variables\n",
    "\n",
    "num_rounds = 20000\n",
    "\n",
    "count = np.zeros(env.n_bandits)\n",
    "\n",
    "sum_rewards = np.zeros(env.n_bandits)\n",
    "\n",
    "Q = np.zeros(env.n_bandits)\n",
    "\n",
    "# Initialize alpha and beta values\n",
    "\n",
    "alpha = np.ones(env.n_bandits)\n",
    "beta = np.ones(env.n_bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling(alpha,beta):\n",
    "    samples = [np.random.beta(alpha[i]+1,beta[i]+1) for i in range(env.n_bandits)]\n",
    "    return np.argmax(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal arm is 4\n"
     ]
    }
   ],
   "source": [
    "# Start pulling the arm\n",
    "for i in range(num_rounds):\n",
    "    # Select the arm using thompson sampling\n",
    "    arm = thompson_sampling(alpha,beta)\n",
    "    # Get the rewards\n",
    "    observation, reward, done, info = env.step(arm)\n",
    "    # Update the count of that arm\n",
    "    count[arm] +=1 \n",
    "    #Sum the rewards obtained from that arm\n",
    "    sum_rewards[arm] +=reward\n",
    "    #Calculate the Q value which is the average rewards of the arm\n",
    "    Q[arm] = sum_rewards[arm]/count[arm]\n",
    "    \n",
    "    if reward>0:\n",
    "        alpha[arm] +=1\n",
    "    else:\n",
    "        beta[arm] +=1\n",
    "print('The optimal arm is {}'.format(np.argmax(Q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of MAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the right advertisement banner using MAB\n",
    "\n",
    "Let us say you are running a website and you have five different banners for the same ad,\n",
    "and you want to know which banner attracts the user. We model this problem statement as\n",
    "a bandit problem. Let us say these five banners are the five arms of the bandit and we\n",
    "award one point if the user clicks the ad and award zero if the user does not click the ad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Banner_0'] = np.random.randint(0,2,100000)\n",
    "df['Banner_1'] = np.random.randint(0,2,100000)\n",
    "df['Banner_2'] = np.random.randint(0,2,100000)\n",
    "df['Banner_3'] = np.random.randint(0,2,100000)\n",
    "df['Banner_4'] = np.random.randint(0,2,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Banner_0</th>\n",
       "      <th>Banner_1</th>\n",
       "      <th>Banner_2</th>\n",
       "      <th>Banner_3</th>\n",
       "      <th>Banner_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Banner_0  Banner_1  Banner_2  Banner_3  Banner_4\n",
       "0         0         0         1         0         1\n",
       "1         0         0         0         0         0\n",
       "2         0         1         1         1         1\n",
       "3         1         1         1         1         0\n",
       "4         1         1         0         0         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first initialize all the variables\n",
    "\n",
    "num_banner = 5\n",
    "\n",
    "no_of_iterations = 100000\n",
    "\n",
    "banner_selected = []\n",
    "\n",
    "count = np.zeros(num_banner)\n",
    "\n",
    "sum_rewards = np.zeros(env.n_bandits)\n",
    "\n",
    "Q = np.zeros(env.n_bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(epsilon):\n",
    "    rand = np.random.random()\n",
    "    if rand < epsilon:\n",
    "        action = np.random.choice(num_banner)\n",
    "    else:\n",
    "        action = np.argmax(Q)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fde663e0048>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start pulling the arm\n",
    "for i in range(no_of_iterations):\n",
    "    # Select the arm using epsilon greedy\n",
    "    banner = epsilon_greedy(0.5)\n",
    "    # Get the rewards\n",
    "    reward = df.values[i,banner]\n",
    "    # Update the count of that arm\n",
    "    count[banner] +=1 \n",
    "    #Sum the rewards obtained from that arm\n",
    "    sum_rewards[banner] +=reward\n",
    "    #Calculate the Q value which is the average rewards of the arm\n",
    "    Q[banner] = sum_rewards[banner]/count[banner]\n",
    "    banner_selected.append(banner)\n",
    "sns.distplot(banner_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
